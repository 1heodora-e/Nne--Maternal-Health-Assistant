{
  "best_global_step": 2336,
  "best_metric": 1.477357268333435,
  "best_model_checkpoint": "outputs_nne/nne_exp2_high_lr/checkpoint-2336",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2336,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008565310492505354,
      "grad_norm": 1.1293220520019531,
      "learning_rate": 7.692307692307694e-06,
      "loss": 3.1196,
      "step": 10
    },
    {
      "epoch": 0.017130620985010708,
      "grad_norm": 1.2374036312103271,
      "learning_rate": 1.623931623931624e-05,
      "loss": 2.9174,
      "step": 20
    },
    {
      "epoch": 0.02569593147751606,
      "grad_norm": 1.0755770206451416,
      "learning_rate": 2.4786324786324787e-05,
      "loss": 2.8711,
      "step": 30
    },
    {
      "epoch": 0.034261241970021415,
      "grad_norm": 1.1438437700271606,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.5998,
      "step": 40
    },
    {
      "epoch": 0.042826552462526764,
      "grad_norm": 1.4129929542541504,
      "learning_rate": 4.1880341880341886e-05,
      "loss": 2.4848,
      "step": 50
    },
    {
      "epoch": 0.05139186295503212,
      "grad_norm": 1.09464693069458,
      "learning_rate": 5.042735042735043e-05,
      "loss": 2.3934,
      "step": 60
    },
    {
      "epoch": 0.059957173447537475,
      "grad_norm": 0.9553727507591248,
      "learning_rate": 5.897435897435898e-05,
      "loss": 1.9129,
      "step": 70
    },
    {
      "epoch": 0.06852248394004283,
      "grad_norm": 0.8203933835029602,
      "learning_rate": 6.752136752136753e-05,
      "loss": 1.7866,
      "step": 80
    },
    {
      "epoch": 0.07708779443254818,
      "grad_norm": 0.8082346320152283,
      "learning_rate": 7.606837606837607e-05,
      "loss": 1.6086,
      "step": 90
    },
    {
      "epoch": 0.08565310492505353,
      "grad_norm": 0.7313781380653381,
      "learning_rate": 8.461538461538461e-05,
      "loss": 1.7184,
      "step": 100
    },
    {
      "epoch": 0.09421841541755889,
      "grad_norm": 0.6124398708343506,
      "learning_rate": 9.316239316239317e-05,
      "loss": 1.5667,
      "step": 110
    },
    {
      "epoch": 0.10278372591006424,
      "grad_norm": 0.7939331531524658,
      "learning_rate": 9.990986931050022e-05,
      "loss": 1.6999,
      "step": 120
    },
    {
      "epoch": 0.11134903640256959,
      "grad_norm": 0.752505898475647,
      "learning_rate": 9.945921586300135e-05,
      "loss": 1.7245,
      "step": 130
    },
    {
      "epoch": 0.11991434689507495,
      "grad_norm": 0.7032214403152466,
      "learning_rate": 9.900856241550249e-05,
      "loss": 1.6695,
      "step": 140
    },
    {
      "epoch": 0.1284796573875803,
      "grad_norm": 0.8555830717086792,
      "learning_rate": 9.85579089680036e-05,
      "loss": 1.6339,
      "step": 150
    },
    {
      "epoch": 0.13704496788008566,
      "grad_norm": 0.6231279969215393,
      "learning_rate": 9.810725552050474e-05,
      "loss": 1.7096,
      "step": 160
    },
    {
      "epoch": 0.145610278372591,
      "grad_norm": 0.8444440364837646,
      "learning_rate": 9.765660207300586e-05,
      "loss": 1.5412,
      "step": 170
    },
    {
      "epoch": 0.15417558886509636,
      "grad_norm": 0.6882805824279785,
      "learning_rate": 9.720594862550699e-05,
      "loss": 1.6214,
      "step": 180
    },
    {
      "epoch": 0.16274089935760172,
      "grad_norm": 0.7651384472846985,
      "learning_rate": 9.675529517800813e-05,
      "loss": 1.5707,
      "step": 190
    },
    {
      "epoch": 0.17130620985010706,
      "grad_norm": 0.7237261533737183,
      "learning_rate": 9.630464173050925e-05,
      "loss": 1.5302,
      "step": 200
    },
    {
      "epoch": 0.17987152034261242,
      "grad_norm": 0.7273069620132446,
      "learning_rate": 9.585398828301037e-05,
      "loss": 1.6612,
      "step": 210
    },
    {
      "epoch": 0.18843683083511778,
      "grad_norm": 0.7945975065231323,
      "learning_rate": 9.54033348355115e-05,
      "loss": 1.5591,
      "step": 220
    },
    {
      "epoch": 0.19700214132762311,
      "grad_norm": 0.887984573841095,
      "learning_rate": 9.495268138801262e-05,
      "loss": 1.5807,
      "step": 230
    },
    {
      "epoch": 0.20556745182012848,
      "grad_norm": 0.788874626159668,
      "learning_rate": 9.450202794051375e-05,
      "loss": 1.4866,
      "step": 240
    },
    {
      "epoch": 0.21413276231263384,
      "grad_norm": 0.8218352198600769,
      "learning_rate": 9.405137449301487e-05,
      "loss": 1.4491,
      "step": 250
    },
    {
      "epoch": 0.22269807280513917,
      "grad_norm": 0.8343517184257507,
      "learning_rate": 9.3600721045516e-05,
      "loss": 1.5961,
      "step": 260
    },
    {
      "epoch": 0.23126338329764454,
      "grad_norm": 0.8346872925758362,
      "learning_rate": 9.315006759801714e-05,
      "loss": 1.6958,
      "step": 270
    },
    {
      "epoch": 0.2398286937901499,
      "grad_norm": 0.6948093175888062,
      "learning_rate": 9.269941415051826e-05,
      "loss": 1.6659,
      "step": 280
    },
    {
      "epoch": 0.24839400428265523,
      "grad_norm": 0.6990008354187012,
      "learning_rate": 9.224876070301939e-05,
      "loss": 1.7459,
      "step": 290
    },
    {
      "epoch": 0.2569593147751606,
      "grad_norm": 0.7007930278778076,
      "learning_rate": 9.179810725552051e-05,
      "loss": 1.6477,
      "step": 300
    },
    {
      "epoch": 0.26552462526766596,
      "grad_norm": 0.6341295838356018,
      "learning_rate": 9.134745380802163e-05,
      "loss": 1.4061,
      "step": 310
    },
    {
      "epoch": 0.2740899357601713,
      "grad_norm": 0.6669114828109741,
      "learning_rate": 9.089680036052276e-05,
      "loss": 1.6107,
      "step": 320
    },
    {
      "epoch": 0.2826552462526767,
      "grad_norm": 0.7827123999595642,
      "learning_rate": 9.044614691302388e-05,
      "loss": 1.5219,
      "step": 330
    },
    {
      "epoch": 0.291220556745182,
      "grad_norm": 0.7850533127784729,
      "learning_rate": 8.999549346552502e-05,
      "loss": 1.6712,
      "step": 340
    },
    {
      "epoch": 0.29978586723768735,
      "grad_norm": 0.8504790663719177,
      "learning_rate": 8.954484001802615e-05,
      "loss": 1.6354,
      "step": 350
    },
    {
      "epoch": 0.3083511777301927,
      "grad_norm": 0.7748332619667053,
      "learning_rate": 8.909418657052727e-05,
      "loss": 1.562,
      "step": 360
    },
    {
      "epoch": 0.3169164882226981,
      "grad_norm": 0.7512773871421814,
      "learning_rate": 8.86435331230284e-05,
      "loss": 1.6691,
      "step": 370
    },
    {
      "epoch": 0.32548179871520344,
      "grad_norm": 0.8614809513092041,
      "learning_rate": 8.819287967552952e-05,
      "loss": 1.4444,
      "step": 380
    },
    {
      "epoch": 0.3340471092077088,
      "grad_norm": 0.9004563689231873,
      "learning_rate": 8.774222622803064e-05,
      "loss": 1.6005,
      "step": 390
    },
    {
      "epoch": 0.3426124197002141,
      "grad_norm": 0.8203999996185303,
      "learning_rate": 8.729157278053177e-05,
      "loss": 1.5029,
      "step": 400
    },
    {
      "epoch": 0.3511777301927195,
      "grad_norm": 0.902726411819458,
      "learning_rate": 8.684091933303289e-05,
      "loss": 1.4099,
      "step": 410
    },
    {
      "epoch": 0.35974304068522484,
      "grad_norm": 0.7868928909301758,
      "learning_rate": 8.639026588553403e-05,
      "loss": 1.5698,
      "step": 420
    },
    {
      "epoch": 0.3683083511777302,
      "grad_norm": 0.8516673445701599,
      "learning_rate": 8.593961243803516e-05,
      "loss": 1.6696,
      "step": 430
    },
    {
      "epoch": 0.37687366167023556,
      "grad_norm": 0.7523463368415833,
      "learning_rate": 8.548895899053628e-05,
      "loss": 1.4591,
      "step": 440
    },
    {
      "epoch": 0.3854389721627409,
      "grad_norm": 0.7555617094039917,
      "learning_rate": 8.503830554303741e-05,
      "loss": 1.5672,
      "step": 450
    },
    {
      "epoch": 0.39400428265524623,
      "grad_norm": 0.7448047995567322,
      "learning_rate": 8.458765209553853e-05,
      "loss": 1.6362,
      "step": 460
    },
    {
      "epoch": 0.4025695931477516,
      "grad_norm": 0.7250834107398987,
      "learning_rate": 8.413699864803967e-05,
      "loss": 1.5162,
      "step": 470
    },
    {
      "epoch": 0.41113490364025695,
      "grad_norm": 0.7308099865913391,
      "learning_rate": 8.368634520054078e-05,
      "loss": 1.5461,
      "step": 480
    },
    {
      "epoch": 0.4197002141327623,
      "grad_norm": 0.7591457366943359,
      "learning_rate": 8.32356917530419e-05,
      "loss": 1.6222,
      "step": 490
    },
    {
      "epoch": 0.4282655246252677,
      "grad_norm": 0.7788330912590027,
      "learning_rate": 8.278503830554304e-05,
      "loss": 1.7213,
      "step": 500
    },
    {
      "epoch": 0.43683083511777304,
      "grad_norm": 0.7616892457008362,
      "learning_rate": 8.233438485804417e-05,
      "loss": 1.5714,
      "step": 510
    },
    {
      "epoch": 0.44539614561027835,
      "grad_norm": 0.7596190571784973,
      "learning_rate": 8.188373141054529e-05,
      "loss": 1.5667,
      "step": 520
    },
    {
      "epoch": 0.4539614561027837,
      "grad_norm": 0.7237843871116638,
      "learning_rate": 8.143307796304642e-05,
      "loss": 1.5424,
      "step": 530
    },
    {
      "epoch": 0.4625267665952891,
      "grad_norm": 0.7724266648292542,
      "learning_rate": 8.098242451554756e-05,
      "loss": 1.4841,
      "step": 540
    },
    {
      "epoch": 0.47109207708779444,
      "grad_norm": 0.8442334532737732,
      "learning_rate": 8.053177106804868e-05,
      "loss": 1.504,
      "step": 550
    },
    {
      "epoch": 0.4796573875802998,
      "grad_norm": 0.7304705381393433,
      "learning_rate": 8.008111762054981e-05,
      "loss": 1.29,
      "step": 560
    },
    {
      "epoch": 0.48822269807280516,
      "grad_norm": 0.7294108271598816,
      "learning_rate": 7.963046417305093e-05,
      "loss": 1.4883,
      "step": 570
    },
    {
      "epoch": 0.49678800856531047,
      "grad_norm": 0.7287592887878418,
      "learning_rate": 7.917981072555205e-05,
      "loss": 1.5957,
      "step": 580
    },
    {
      "epoch": 0.5053533190578159,
      "grad_norm": 0.769774317741394,
      "learning_rate": 7.872915727805318e-05,
      "loss": 1.5626,
      "step": 590
    },
    {
      "epoch": 0.5139186295503212,
      "grad_norm": 0.8254895806312561,
      "learning_rate": 7.82785038305543e-05,
      "loss": 1.5863,
      "step": 600
    },
    {
      "epoch": 0.5224839400428265,
      "grad_norm": 0.7558397650718689,
      "learning_rate": 7.782785038305543e-05,
      "loss": 1.4512,
      "step": 610
    },
    {
      "epoch": 0.5310492505353319,
      "grad_norm": 0.7562167048454285,
      "learning_rate": 7.737719693555657e-05,
      "loss": 1.4046,
      "step": 620
    },
    {
      "epoch": 0.5396145610278372,
      "grad_norm": 0.7081997394561768,
      "learning_rate": 7.692654348805769e-05,
      "loss": 1.5316,
      "step": 630
    },
    {
      "epoch": 0.5481798715203426,
      "grad_norm": 0.7822368144989014,
      "learning_rate": 7.647589004055882e-05,
      "loss": 1.4722,
      "step": 640
    },
    {
      "epoch": 0.556745182012848,
      "grad_norm": 0.7227791547775269,
      "learning_rate": 7.602523659305994e-05,
      "loss": 1.5311,
      "step": 650
    },
    {
      "epoch": 0.5653104925053534,
      "grad_norm": 0.7902345061302185,
      "learning_rate": 7.557458314556106e-05,
      "loss": 1.4429,
      "step": 660
    },
    {
      "epoch": 0.5738758029978587,
      "grad_norm": 0.6761276125907898,
      "learning_rate": 7.51239296980622e-05,
      "loss": 1.4754,
      "step": 670
    },
    {
      "epoch": 0.582441113490364,
      "grad_norm": 0.7284558415412903,
      "learning_rate": 7.467327625056331e-05,
      "loss": 1.4692,
      "step": 680
    },
    {
      "epoch": 0.5910064239828694,
      "grad_norm": 0.7337095737457275,
      "learning_rate": 7.422262280306445e-05,
      "loss": 1.542,
      "step": 690
    },
    {
      "epoch": 0.5995717344753747,
      "grad_norm": 0.7409453392028809,
      "learning_rate": 7.377196935556558e-05,
      "loss": 1.6299,
      "step": 700
    },
    {
      "epoch": 0.6081370449678801,
      "grad_norm": 0.7770983576774597,
      "learning_rate": 7.33213159080667e-05,
      "loss": 1.5317,
      "step": 710
    },
    {
      "epoch": 0.6167023554603854,
      "grad_norm": 0.745216429233551,
      "learning_rate": 7.287066246056783e-05,
      "loss": 1.4983,
      "step": 720
    },
    {
      "epoch": 0.6252676659528907,
      "grad_norm": 0.8451770544052124,
      "learning_rate": 7.242000901306895e-05,
      "loss": 1.6102,
      "step": 730
    },
    {
      "epoch": 0.6338329764453962,
      "grad_norm": 0.7896787524223328,
      "learning_rate": 7.196935556557008e-05,
      "loss": 1.534,
      "step": 740
    },
    {
      "epoch": 0.6423982869379015,
      "grad_norm": 0.8473169803619385,
      "learning_rate": 7.15187021180712e-05,
      "loss": 1.6718,
      "step": 750
    },
    {
      "epoch": 0.6509635974304069,
      "grad_norm": 0.8342311382293701,
      "learning_rate": 7.106804867057232e-05,
      "loss": 1.4477,
      "step": 760
    },
    {
      "epoch": 0.6595289079229122,
      "grad_norm": 0.84610915184021,
      "learning_rate": 7.061739522307346e-05,
      "loss": 1.4006,
      "step": 770
    },
    {
      "epoch": 0.6680942184154176,
      "grad_norm": 0.7733731269836426,
      "learning_rate": 7.016674177557459e-05,
      "loss": 1.5484,
      "step": 780
    },
    {
      "epoch": 0.6766595289079229,
      "grad_norm": 0.7983523011207581,
      "learning_rate": 6.971608832807571e-05,
      "loss": 1.526,
      "step": 790
    },
    {
      "epoch": 0.6852248394004282,
      "grad_norm": 0.669215977191925,
      "learning_rate": 6.926543488057684e-05,
      "loss": 1.5537,
      "step": 800
    },
    {
      "epoch": 0.6937901498929336,
      "grad_norm": 0.7070121765136719,
      "learning_rate": 6.881478143307796e-05,
      "loss": 1.5236,
      "step": 810
    },
    {
      "epoch": 0.702355460385439,
      "grad_norm": 0.7660633325576782,
      "learning_rate": 6.83641279855791e-05,
      "loss": 1.4985,
      "step": 820
    },
    {
      "epoch": 0.7109207708779444,
      "grad_norm": 0.6315531730651855,
      "learning_rate": 6.791347453808023e-05,
      "loss": 1.5572,
      "step": 830
    },
    {
      "epoch": 0.7194860813704497,
      "grad_norm": 0.6913293600082397,
      "learning_rate": 6.746282109058134e-05,
      "loss": 1.5278,
      "step": 840
    },
    {
      "epoch": 0.728051391862955,
      "grad_norm": 0.7944601774215698,
      "learning_rate": 6.701216764308247e-05,
      "loss": 1.498,
      "step": 850
    },
    {
      "epoch": 0.7366167023554604,
      "grad_norm": 0.9485140442848206,
      "learning_rate": 6.65615141955836e-05,
      "loss": 1.5707,
      "step": 860
    },
    {
      "epoch": 0.7451820128479657,
      "grad_norm": 0.8137423992156982,
      "learning_rate": 6.611086074808472e-05,
      "loss": 1.6393,
      "step": 870
    },
    {
      "epoch": 0.7537473233404711,
      "grad_norm": 0.8314968347549438,
      "learning_rate": 6.566020730058585e-05,
      "loss": 1.578,
      "step": 880
    },
    {
      "epoch": 0.7623126338329764,
      "grad_norm": 0.794853925704956,
      "learning_rate": 6.520955385308697e-05,
      "loss": 1.5961,
      "step": 890
    },
    {
      "epoch": 0.7708779443254818,
      "grad_norm": 0.7887436151504517,
      "learning_rate": 6.475890040558811e-05,
      "loss": 1.6414,
      "step": 900
    },
    {
      "epoch": 0.7794432548179872,
      "grad_norm": 0.8325908184051514,
      "learning_rate": 6.430824695808924e-05,
      "loss": 1.6104,
      "step": 910
    },
    {
      "epoch": 0.7880085653104925,
      "grad_norm": 0.7706311941146851,
      "learning_rate": 6.385759351059036e-05,
      "loss": 1.43,
      "step": 920
    },
    {
      "epoch": 0.7965738758029979,
      "grad_norm": 0.7421631217002869,
      "learning_rate": 6.34069400630915e-05,
      "loss": 1.731,
      "step": 930
    },
    {
      "epoch": 0.8051391862955032,
      "grad_norm": 0.8399296998977661,
      "learning_rate": 6.295628661559261e-05,
      "loss": 1.4478,
      "step": 940
    },
    {
      "epoch": 0.8137044967880086,
      "grad_norm": 0.7759097218513489,
      "learning_rate": 6.250563316809373e-05,
      "loss": 1.4641,
      "step": 950
    },
    {
      "epoch": 0.8222698072805139,
      "grad_norm": 0.7985116839408875,
      "learning_rate": 6.205497972059487e-05,
      "loss": 1.642,
      "step": 960
    },
    {
      "epoch": 0.8308351177730193,
      "grad_norm": 0.8221399188041687,
      "learning_rate": 6.160432627309599e-05,
      "loss": 1.6527,
      "step": 970
    },
    {
      "epoch": 0.8394004282655246,
      "grad_norm": 0.8118009567260742,
      "learning_rate": 6.115367282559712e-05,
      "loss": 1.6216,
      "step": 980
    },
    {
      "epoch": 0.8479657387580299,
      "grad_norm": 0.8193336129188538,
      "learning_rate": 6.0703019378098245e-05,
      "loss": 1.4991,
      "step": 990
    },
    {
      "epoch": 0.8565310492505354,
      "grad_norm": 0.8225547671318054,
      "learning_rate": 6.025236593059937e-05,
      "loss": 1.606,
      "step": 1000
    },
    {
      "epoch": 0.8650963597430407,
      "grad_norm": 0.8435539603233337,
      "learning_rate": 5.9801712483100505e-05,
      "loss": 1.5106,
      "step": 1010
    },
    {
      "epoch": 0.8736616702355461,
      "grad_norm": 0.787751317024231,
      "learning_rate": 5.935105903560163e-05,
      "loss": 1.5867,
      "step": 1020
    },
    {
      "epoch": 0.8822269807280514,
      "grad_norm": 0.7960286736488342,
      "learning_rate": 5.8900405588102744e-05,
      "loss": 1.6541,
      "step": 1030
    },
    {
      "epoch": 0.8907922912205567,
      "grad_norm": 0.5941848754882812,
      "learning_rate": 5.844975214060388e-05,
      "loss": 1.4345,
      "step": 1040
    },
    {
      "epoch": 0.8993576017130621,
      "grad_norm": 0.8133092522621155,
      "learning_rate": 5.7999098693105004e-05,
      "loss": 1.5704,
      "step": 1050
    },
    {
      "epoch": 0.9079229122055674,
      "grad_norm": 0.7475671768188477,
      "learning_rate": 5.754844524560613e-05,
      "loss": 1.5228,
      "step": 1060
    },
    {
      "epoch": 0.9164882226980728,
      "grad_norm": 0.7967726588249207,
      "learning_rate": 5.7097791798107256e-05,
      "loss": 1.7172,
      "step": 1070
    },
    {
      "epoch": 0.9250535331905781,
      "grad_norm": 0.7912998795509338,
      "learning_rate": 5.664713835060839e-05,
      "loss": 1.4574,
      "step": 1080
    },
    {
      "epoch": 0.9336188436830836,
      "grad_norm": 0.7667267918586731,
      "learning_rate": 5.6196484903109516e-05,
      "loss": 1.5327,
      "step": 1090
    },
    {
      "epoch": 0.9421841541755889,
      "grad_norm": 0.8932487368583679,
      "learning_rate": 5.574583145561064e-05,
      "loss": 1.6317,
      "step": 1100
    },
    {
      "epoch": 0.9507494646680942,
      "grad_norm": 0.7684940099716187,
      "learning_rate": 5.529517800811177e-05,
      "loss": 1.6299,
      "step": 1110
    },
    {
      "epoch": 0.9593147751605996,
      "grad_norm": 0.8092303276062012,
      "learning_rate": 5.484452456061289e-05,
      "loss": 1.3215,
      "step": 1120
    },
    {
      "epoch": 0.9678800856531049,
      "grad_norm": 0.7707965970039368,
      "learning_rate": 5.4393871113114015e-05,
      "loss": 1.5176,
      "step": 1130
    },
    {
      "epoch": 0.9764453961456103,
      "grad_norm": 0.803207516670227,
      "learning_rate": 5.394321766561514e-05,
      "loss": 1.4686,
      "step": 1140
    },
    {
      "epoch": 0.9850107066381156,
      "grad_norm": 0.7581740021705627,
      "learning_rate": 5.349256421811627e-05,
      "loss": 1.566,
      "step": 1150
    },
    {
      "epoch": 0.9935760171306209,
      "grad_norm": 0.87521892786026,
      "learning_rate": 5.30419107706174e-05,
      "loss": 1.5529,
      "step": 1160
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.490552544593811,
      "eval_runtime": 44.6616,
      "eval_samples_per_second": 26.152,
      "eval_steps_per_second": 6.538,
      "step": 1168
    },
    {
      "epoch": 1.001713062098501,
      "grad_norm": 0.7376918792724609,
      "learning_rate": 5.259125732311853e-05,
      "loss": 1.455,
      "step": 1170
    },
    {
      "epoch": 1.0102783725910065,
      "grad_norm": 0.6038380265235901,
      "learning_rate": 5.2140603875619654e-05,
      "loss": 1.6145,
      "step": 1180
    },
    {
      "epoch": 1.0188436830835117,
      "grad_norm": 0.8002625107765198,
      "learning_rate": 5.168995042812078e-05,
      "loss": 1.5212,
      "step": 1190
    },
    {
      "epoch": 1.0274089935760171,
      "grad_norm": 0.8242619037628174,
      "learning_rate": 5.1239296980621906e-05,
      "loss": 1.5625,
      "step": 1200
    },
    {
      "epoch": 1.0359743040685225,
      "grad_norm": 0.744975745677948,
      "learning_rate": 5.0788643533123026e-05,
      "loss": 1.311,
      "step": 1210
    },
    {
      "epoch": 1.0445396145610277,
      "grad_norm": 0.816082775592804,
      "learning_rate": 5.033799008562415e-05,
      "loss": 1.3982,
      "step": 1220
    },
    {
      "epoch": 1.0531049250535331,
      "grad_norm": 0.8543257713317871,
      "learning_rate": 4.988733663812528e-05,
      "loss": 1.5911,
      "step": 1230
    },
    {
      "epoch": 1.0616702355460386,
      "grad_norm": 0.842369556427002,
      "learning_rate": 4.943668319062641e-05,
      "loss": 1.5332,
      "step": 1240
    },
    {
      "epoch": 1.070235546038544,
      "grad_norm": 0.7773188948631287,
      "learning_rate": 4.898602974312754e-05,
      "loss": 1.5441,
      "step": 1250
    },
    {
      "epoch": 1.0788008565310492,
      "grad_norm": 0.7304030656814575,
      "learning_rate": 4.8535376295628665e-05,
      "loss": 1.5971,
      "step": 1260
    },
    {
      "epoch": 1.0873661670235546,
      "grad_norm": 0.8354085087776184,
      "learning_rate": 4.808472284812979e-05,
      "loss": 1.3707,
      "step": 1270
    },
    {
      "epoch": 1.09593147751606,
      "grad_norm": 0.778481125831604,
      "learning_rate": 4.763406940063092e-05,
      "loss": 1.6537,
      "step": 1280
    },
    {
      "epoch": 1.1044967880085652,
      "grad_norm": 0.9154276251792908,
      "learning_rate": 4.7183415953132044e-05,
      "loss": 1.4492,
      "step": 1290
    },
    {
      "epoch": 1.1130620985010706,
      "grad_norm": 0.8195778131484985,
      "learning_rate": 4.673276250563317e-05,
      "loss": 1.5501,
      "step": 1300
    },
    {
      "epoch": 1.121627408993576,
      "grad_norm": 0.8801270127296448,
      "learning_rate": 4.62821090581343e-05,
      "loss": 1.491,
      "step": 1310
    },
    {
      "epoch": 1.1301927194860815,
      "grad_norm": 0.7427895665168762,
      "learning_rate": 4.583145561063542e-05,
      "loss": 1.5628,
      "step": 1320
    },
    {
      "epoch": 1.1387580299785867,
      "grad_norm": 0.9059789180755615,
      "learning_rate": 4.538080216313655e-05,
      "loss": 1.4587,
      "step": 1330
    },
    {
      "epoch": 1.147323340471092,
      "grad_norm": 0.9065167307853699,
      "learning_rate": 4.4930148715637676e-05,
      "loss": 1.4657,
      "step": 1340
    },
    {
      "epoch": 1.1558886509635975,
      "grad_norm": 0.8185286521911621,
      "learning_rate": 4.44794952681388e-05,
      "loss": 1.6863,
      "step": 1350
    },
    {
      "epoch": 1.1644539614561027,
      "grad_norm": 0.7899765372276306,
      "learning_rate": 4.402884182063993e-05,
      "loss": 1.5846,
      "step": 1360
    },
    {
      "epoch": 1.173019271948608,
      "grad_norm": 0.8096567392349243,
      "learning_rate": 4.3578188373141055e-05,
      "loss": 1.4572,
      "step": 1370
    },
    {
      "epoch": 1.1815845824411135,
      "grad_norm": 0.8404589295387268,
      "learning_rate": 4.312753492564218e-05,
      "loss": 1.4688,
      "step": 1380
    },
    {
      "epoch": 1.190149892933619,
      "grad_norm": 0.8320059776306152,
      "learning_rate": 4.267688147814331e-05,
      "loss": 1.5182,
      "step": 1390
    },
    {
      "epoch": 1.1987152034261241,
      "grad_norm": 0.8102021217346191,
      "learning_rate": 4.2226228030644435e-05,
      "loss": 1.503,
      "step": 1400
    },
    {
      "epoch": 1.2072805139186296,
      "grad_norm": 0.738654613494873,
      "learning_rate": 4.177557458314557e-05,
      "loss": 1.6052,
      "step": 1410
    },
    {
      "epoch": 1.215845824411135,
      "grad_norm": 0.8586146235466003,
      "learning_rate": 4.132492113564669e-05,
      "loss": 1.4401,
      "step": 1420
    },
    {
      "epoch": 1.2244111349036402,
      "grad_norm": 0.9339284300804138,
      "learning_rate": 4.0874267688147814e-05,
      "loss": 1.42,
      "step": 1430
    },
    {
      "epoch": 1.2329764453961456,
      "grad_norm": 0.8439951539039612,
      "learning_rate": 4.042361424064895e-05,
      "loss": 1.5174,
      "step": 1440
    },
    {
      "epoch": 1.241541755888651,
      "grad_norm": 0.8478004336357117,
      "learning_rate": 3.9972960793150073e-05,
      "loss": 1.4771,
      "step": 1450
    },
    {
      "epoch": 1.2501070663811564,
      "grad_norm": 0.9871693253517151,
      "learning_rate": 3.952230734565119e-05,
      "loss": 1.3892,
      "step": 1460
    },
    {
      "epoch": 1.2586723768736616,
      "grad_norm": 0.8173276782035828,
      "learning_rate": 3.907165389815232e-05,
      "loss": 1.438,
      "step": 1470
    },
    {
      "epoch": 1.267237687366167,
      "grad_norm": 0.8347596526145935,
      "learning_rate": 3.862100045065345e-05,
      "loss": 1.4675,
      "step": 1480
    },
    {
      "epoch": 1.2758029978586722,
      "grad_norm": 0.7903671264648438,
      "learning_rate": 3.817034700315458e-05,
      "loss": 1.4376,
      "step": 1490
    },
    {
      "epoch": 1.2843683083511777,
      "grad_norm": 0.7152621746063232,
      "learning_rate": 3.7719693555655705e-05,
      "loss": 1.5902,
      "step": 1500
    },
    {
      "epoch": 1.292933618843683,
      "grad_norm": 0.7273138761520386,
      "learning_rate": 3.7269040108156825e-05,
      "loss": 1.5387,
      "step": 1510
    },
    {
      "epoch": 1.3014989293361885,
      "grad_norm": 0.7569705843925476,
      "learning_rate": 3.681838666065796e-05,
      "loss": 1.4552,
      "step": 1520
    },
    {
      "epoch": 1.310064239828694,
      "grad_norm": 0.8322842121124268,
      "learning_rate": 3.6367733213159085e-05,
      "loss": 1.5542,
      "step": 1530
    },
    {
      "epoch": 1.318629550321199,
      "grad_norm": 0.8786759972572327,
      "learning_rate": 3.591707976566021e-05,
      "loss": 1.4881,
      "step": 1540
    },
    {
      "epoch": 1.3271948608137045,
      "grad_norm": 0.816482663154602,
      "learning_rate": 3.546642631816133e-05,
      "loss": 1.4428,
      "step": 1550
    },
    {
      "epoch": 1.3357601713062097,
      "grad_norm": 0.912572979927063,
      "learning_rate": 3.5015772870662464e-05,
      "loss": 1.5419,
      "step": 1560
    },
    {
      "epoch": 1.3443254817987151,
      "grad_norm": 0.8837666511535645,
      "learning_rate": 3.456511942316359e-05,
      "loss": 1.4388,
      "step": 1570
    },
    {
      "epoch": 1.3528907922912206,
      "grad_norm": 0.7379298806190491,
      "learning_rate": 3.411446597566472e-05,
      "loss": 1.7055,
      "step": 1580
    },
    {
      "epoch": 1.361456102783726,
      "grad_norm": 0.8035628795623779,
      "learning_rate": 3.366381252816584e-05,
      "loss": 1.4067,
      "step": 1590
    },
    {
      "epoch": 1.3700214132762314,
      "grad_norm": 0.8410205245018005,
      "learning_rate": 3.321315908066697e-05,
      "loss": 1.4435,
      "step": 1600
    },
    {
      "epoch": 1.3785867237687366,
      "grad_norm": 0.8833736777305603,
      "learning_rate": 3.2762505633168096e-05,
      "loss": 1.3575,
      "step": 1610
    },
    {
      "epoch": 1.387152034261242,
      "grad_norm": 0.8660449385643005,
      "learning_rate": 3.231185218566922e-05,
      "loss": 1.5133,
      "step": 1620
    },
    {
      "epoch": 1.3957173447537472,
      "grad_norm": 0.766452431678772,
      "learning_rate": 3.186119873817035e-05,
      "loss": 1.5337,
      "step": 1630
    },
    {
      "epoch": 1.4042826552462526,
      "grad_norm": 0.8033689260482788,
      "learning_rate": 3.1410545290671475e-05,
      "loss": 1.5714,
      "step": 1640
    },
    {
      "epoch": 1.412847965738758,
      "grad_norm": 0.811876654624939,
      "learning_rate": 3.09598918431726e-05,
      "loss": 1.409,
      "step": 1650
    },
    {
      "epoch": 1.4214132762312635,
      "grad_norm": 0.8824920058250427,
      "learning_rate": 3.0509238395673728e-05,
      "loss": 1.6132,
      "step": 1660
    },
    {
      "epoch": 1.4299785867237689,
      "grad_norm": 0.9618276357650757,
      "learning_rate": 3.0058584948174854e-05,
      "loss": 1.5598,
      "step": 1670
    },
    {
      "epoch": 1.438543897216274,
      "grad_norm": 0.9159096479415894,
      "learning_rate": 2.9607931500675984e-05,
      "loss": 1.4707,
      "step": 1680
    },
    {
      "epoch": 1.4471092077087795,
      "grad_norm": 0.7879514694213867,
      "learning_rate": 2.9157278053177107e-05,
      "loss": 1.3872,
      "step": 1690
    },
    {
      "epoch": 1.4556745182012847,
      "grad_norm": 0.7989197969436646,
      "learning_rate": 2.8706624605678234e-05,
      "loss": 1.6185,
      "step": 1700
    },
    {
      "epoch": 1.46423982869379,
      "grad_norm": 0.8832366466522217,
      "learning_rate": 2.8255971158179363e-05,
      "loss": 1.6447,
      "step": 1710
    },
    {
      "epoch": 1.4728051391862955,
      "grad_norm": 0.9861831665039062,
      "learning_rate": 2.780531771068049e-05,
      "loss": 1.5364,
      "step": 1720
    },
    {
      "epoch": 1.481370449678801,
      "grad_norm": 0.8773747682571411,
      "learning_rate": 2.7354664263181613e-05,
      "loss": 1.5433,
      "step": 1730
    },
    {
      "epoch": 1.4899357601713061,
      "grad_norm": 0.9475308656692505,
      "learning_rate": 2.690401081568274e-05,
      "loss": 1.3526,
      "step": 1740
    },
    {
      "epoch": 1.4985010706638116,
      "grad_norm": 0.877072811126709,
      "learning_rate": 2.645335736818387e-05,
      "loss": 1.3914,
      "step": 1750
    },
    {
      "epoch": 1.507066381156317,
      "grad_norm": 0.7567691206932068,
      "learning_rate": 2.6002703920684995e-05,
      "loss": 1.4442,
      "step": 1760
    },
    {
      "epoch": 1.5156316916488222,
      "grad_norm": 0.8556107878684998,
      "learning_rate": 2.5552050473186122e-05,
      "loss": 1.4418,
      "step": 1770
    },
    {
      "epoch": 1.5241970021413276,
      "grad_norm": 0.8407837152481079,
      "learning_rate": 2.5101397025687245e-05,
      "loss": 1.5172,
      "step": 1780
    },
    {
      "epoch": 1.532762312633833,
      "grad_norm": 0.7637636661529541,
      "learning_rate": 2.4650743578188375e-05,
      "loss": 1.4393,
      "step": 1790
    },
    {
      "epoch": 1.5413276231263384,
      "grad_norm": 0.8839852809906006,
      "learning_rate": 2.42000901306895e-05,
      "loss": 1.577,
      "step": 1800
    },
    {
      "epoch": 1.5498929336188438,
      "grad_norm": 0.862065851688385,
      "learning_rate": 2.3749436683190627e-05,
      "loss": 1.5554,
      "step": 1810
    },
    {
      "epoch": 1.558458244111349,
      "grad_norm": 0.7995415329933167,
      "learning_rate": 2.3298783235691754e-05,
      "loss": 1.3756,
      "step": 1820
    },
    {
      "epoch": 1.5670235546038542,
      "grad_norm": 0.8760921359062195,
      "learning_rate": 2.284812978819288e-05,
      "loss": 1.485,
      "step": 1830
    },
    {
      "epoch": 1.5755888650963596,
      "grad_norm": 0.8511075377464294,
      "learning_rate": 2.2397476340694007e-05,
      "loss": 1.5255,
      "step": 1840
    },
    {
      "epoch": 1.584154175588865,
      "grad_norm": 0.9058066010475159,
      "learning_rate": 2.1946822893195133e-05,
      "loss": 1.5497,
      "step": 1850
    },
    {
      "epoch": 1.5927194860813705,
      "grad_norm": 0.8032839298248291,
      "learning_rate": 2.149616944569626e-05,
      "loss": 1.462,
      "step": 1860
    },
    {
      "epoch": 1.601284796573876,
      "grad_norm": 0.992773175239563,
      "learning_rate": 2.1045515998197386e-05,
      "loss": 1.5711,
      "step": 1870
    },
    {
      "epoch": 1.6098501070663813,
      "grad_norm": 0.9443100690841675,
      "learning_rate": 2.0594862550698512e-05,
      "loss": 1.5505,
      "step": 1880
    },
    {
      "epoch": 1.6184154175588865,
      "grad_norm": 0.8327518701553345,
      "learning_rate": 2.0144209103199642e-05,
      "loss": 1.5793,
      "step": 1890
    },
    {
      "epoch": 1.6269807280513917,
      "grad_norm": 0.7771851420402527,
      "learning_rate": 1.969355565570077e-05,
      "loss": 1.5651,
      "step": 1900
    },
    {
      "epoch": 1.6355460385438971,
      "grad_norm": 0.8977965116500854,
      "learning_rate": 1.9242902208201895e-05,
      "loss": 1.3494,
      "step": 1910
    },
    {
      "epoch": 1.6441113490364025,
      "grad_norm": 0.9343527555465698,
      "learning_rate": 1.879224876070302e-05,
      "loss": 1.5698,
      "step": 1920
    },
    {
      "epoch": 1.652676659528908,
      "grad_norm": 0.9367934465408325,
      "learning_rate": 1.8341595313204148e-05,
      "loss": 1.5717,
      "step": 1930
    },
    {
      "epoch": 1.6612419700214134,
      "grad_norm": 0.8180997967720032,
      "learning_rate": 1.7890941865705274e-05,
      "loss": 1.5379,
      "step": 1940
    },
    {
      "epoch": 1.6698072805139186,
      "grad_norm": 0.9730930328369141,
      "learning_rate": 1.74402884182064e-05,
      "loss": 1.4782,
      "step": 1950
    },
    {
      "epoch": 1.678372591006424,
      "grad_norm": 0.8601886034011841,
      "learning_rate": 1.6989634970707527e-05,
      "loss": 1.4723,
      "step": 1960
    },
    {
      "epoch": 1.6869379014989292,
      "grad_norm": 1.025277018547058,
      "learning_rate": 1.6538981523208653e-05,
      "loss": 1.6681,
      "step": 1970
    },
    {
      "epoch": 1.6955032119914346,
      "grad_norm": 0.870137095451355,
      "learning_rate": 1.608832807570978e-05,
      "loss": 1.4631,
      "step": 1980
    },
    {
      "epoch": 1.70406852248394,
      "grad_norm": 0.8617538213729858,
      "learning_rate": 1.5637674628210906e-05,
      "loss": 1.4905,
      "step": 1990
    },
    {
      "epoch": 1.7126338329764454,
      "grad_norm": 0.8935014009475708,
      "learning_rate": 1.5187021180712033e-05,
      "loss": 1.4409,
      "step": 2000
    },
    {
      "epoch": 1.7211991434689509,
      "grad_norm": 0.832368791103363,
      "learning_rate": 1.473636773321316e-05,
      "loss": 1.426,
      "step": 2010
    },
    {
      "epoch": 1.729764453961456,
      "grad_norm": 1.0383634567260742,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 1.434,
      "step": 2020
    },
    {
      "epoch": 1.7383297644539615,
      "grad_norm": 0.943379819393158,
      "learning_rate": 1.3835060838215414e-05,
      "loss": 1.4265,
      "step": 2030
    },
    {
      "epoch": 1.7468950749464667,
      "grad_norm": 0.7896112203598022,
      "learning_rate": 1.3384407390716538e-05,
      "loss": 1.662,
      "step": 2040
    },
    {
      "epoch": 1.755460385438972,
      "grad_norm": 0.812536358833313,
      "learning_rate": 1.2933753943217666e-05,
      "loss": 1.5929,
      "step": 2050
    },
    {
      "epoch": 1.7640256959314775,
      "grad_norm": 0.9202865362167358,
      "learning_rate": 1.2483100495718793e-05,
      "loss": 1.4072,
      "step": 2060
    },
    {
      "epoch": 1.772591006423983,
      "grad_norm": 0.7889044284820557,
      "learning_rate": 1.203244704821992e-05,
      "loss": 1.4494,
      "step": 2070
    },
    {
      "epoch": 1.7811563169164883,
      "grad_norm": 0.811927080154419,
      "learning_rate": 1.1581793600721046e-05,
      "loss": 1.4287,
      "step": 2080
    },
    {
      "epoch": 1.7897216274089935,
      "grad_norm": 0.7727072238922119,
      "learning_rate": 1.1131140153222172e-05,
      "loss": 1.5177,
      "step": 2090
    },
    {
      "epoch": 1.798286937901499,
      "grad_norm": 0.924493134021759,
      "learning_rate": 1.06804867057233e-05,
      "loss": 1.4579,
      "step": 2100
    },
    {
      "epoch": 1.8068522483940042,
      "grad_norm": 0.89675372838974,
      "learning_rate": 1.0229833258224426e-05,
      "loss": 1.4132,
      "step": 2110
    },
    {
      "epoch": 1.8154175588865096,
      "grad_norm": 0.8894488215446472,
      "learning_rate": 9.779179810725553e-06,
      "loss": 1.514,
      "step": 2120
    },
    {
      "epoch": 1.823982869379015,
      "grad_norm": 0.8669878244400024,
      "learning_rate": 9.32852636322668e-06,
      "loss": 1.5179,
      "step": 2130
    },
    {
      "epoch": 1.8325481798715204,
      "grad_norm": 0.8048588633537292,
      "learning_rate": 8.877872915727806e-06,
      "loss": 1.4576,
      "step": 2140
    },
    {
      "epoch": 1.8411134903640258,
      "grad_norm": 0.9398579597473145,
      "learning_rate": 8.427219468228932e-06,
      "loss": 1.5371,
      "step": 2150
    },
    {
      "epoch": 1.849678800856531,
      "grad_norm": 0.9715836644172668,
      "learning_rate": 7.976566020730059e-06,
      "loss": 1.4944,
      "step": 2160
    },
    {
      "epoch": 1.8582441113490364,
      "grad_norm": 0.9780550599098206,
      "learning_rate": 7.525912573231185e-06,
      "loss": 1.5763,
      "step": 2170
    },
    {
      "epoch": 1.8668094218415416,
      "grad_norm": 0.8360995054244995,
      "learning_rate": 7.075259125732313e-06,
      "loss": 1.5393,
      "step": 2180
    },
    {
      "epoch": 1.875374732334047,
      "grad_norm": 0.82589191198349,
      "learning_rate": 6.6246056782334394e-06,
      "loss": 1.4021,
      "step": 2190
    },
    {
      "epoch": 1.8839400428265525,
      "grad_norm": 0.7928253412246704,
      "learning_rate": 6.173952230734566e-06,
      "loss": 1.5825,
      "step": 2200
    },
    {
      "epoch": 1.892505353319058,
      "grad_norm": 0.8358696103096008,
      "learning_rate": 5.723298783235692e-06,
      "loss": 1.5001,
      "step": 2210
    },
    {
      "epoch": 1.9010706638115633,
      "grad_norm": 1.0138825178146362,
      "learning_rate": 5.272645335736819e-06,
      "loss": 1.5817,
      "step": 2220
    },
    {
      "epoch": 1.9096359743040685,
      "grad_norm": 0.8109603524208069,
      "learning_rate": 4.821991888237945e-06,
      "loss": 1.5318,
      "step": 2230
    },
    {
      "epoch": 1.918201284796574,
      "grad_norm": 0.8485430479049683,
      "learning_rate": 4.371338440739072e-06,
      "loss": 1.5311,
      "step": 2240
    },
    {
      "epoch": 1.9267665952890791,
      "grad_norm": 0.926037609577179,
      "learning_rate": 3.920684993240199e-06,
      "loss": 1.5225,
      "step": 2250
    },
    {
      "epoch": 1.9353319057815845,
      "grad_norm": 0.9884530305862427,
      "learning_rate": 3.470031545741325e-06,
      "loss": 1.6319,
      "step": 2260
    },
    {
      "epoch": 1.94389721627409,
      "grad_norm": 0.9012261033058167,
      "learning_rate": 3.019378098242452e-06,
      "loss": 1.5451,
      "step": 2270
    },
    {
      "epoch": 1.9524625267665954,
      "grad_norm": 0.861594557762146,
      "learning_rate": 2.5687246507435784e-06,
      "loss": 1.422,
      "step": 2280
    },
    {
      "epoch": 1.9610278372591008,
      "grad_norm": 0.7437393069267273,
      "learning_rate": 2.118071203244705e-06,
      "loss": 1.5573,
      "step": 2290
    },
    {
      "epoch": 1.969593147751606,
      "grad_norm": 0.9374870657920837,
      "learning_rate": 1.6674177557458314e-06,
      "loss": 1.4156,
      "step": 2300
    },
    {
      "epoch": 1.9781584582441112,
      "grad_norm": 0.7872136235237122,
      "learning_rate": 1.216764308246958e-06,
      "loss": 1.6657,
      "step": 2310
    },
    {
      "epoch": 1.9867237687366166,
      "grad_norm": 0.9398437738418579,
      "learning_rate": 7.661108607480847e-07,
      "loss": 1.4473,
      "step": 2320
    },
    {
      "epoch": 1.995289079229122,
      "grad_norm": 0.83409184217453,
      "learning_rate": 3.1545741324921137e-07,
      "loss": 1.4631,
      "step": 2330
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.477357268333435,
      "eval_runtime": 44.4956,
      "eval_samples_per_second": 26.25,
      "eval_steps_per_second": 6.562,
      "step": 2336
    }
  ],
  "logging_steps": 10,
  "max_steps": 2336,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.163352995486761e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
