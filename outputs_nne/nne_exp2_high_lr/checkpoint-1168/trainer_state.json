{
  "best_global_step": 1168,
  "best_metric": 1.490552544593811,
  "best_model_checkpoint": "outputs_nne/nne_exp2_high_lr/checkpoint-1168",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1168,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008565310492505354,
      "grad_norm": 1.1293220520019531,
      "learning_rate": 7.692307692307694e-06,
      "loss": 3.1196,
      "step": 10
    },
    {
      "epoch": 0.017130620985010708,
      "grad_norm": 1.2374036312103271,
      "learning_rate": 1.623931623931624e-05,
      "loss": 2.9174,
      "step": 20
    },
    {
      "epoch": 0.02569593147751606,
      "grad_norm": 1.0755770206451416,
      "learning_rate": 2.4786324786324787e-05,
      "loss": 2.8711,
      "step": 30
    },
    {
      "epoch": 0.034261241970021415,
      "grad_norm": 1.1438437700271606,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.5998,
      "step": 40
    },
    {
      "epoch": 0.042826552462526764,
      "grad_norm": 1.4129929542541504,
      "learning_rate": 4.1880341880341886e-05,
      "loss": 2.4848,
      "step": 50
    },
    {
      "epoch": 0.05139186295503212,
      "grad_norm": 1.09464693069458,
      "learning_rate": 5.042735042735043e-05,
      "loss": 2.3934,
      "step": 60
    },
    {
      "epoch": 0.059957173447537475,
      "grad_norm": 0.9553727507591248,
      "learning_rate": 5.897435897435898e-05,
      "loss": 1.9129,
      "step": 70
    },
    {
      "epoch": 0.06852248394004283,
      "grad_norm": 0.8203933835029602,
      "learning_rate": 6.752136752136753e-05,
      "loss": 1.7866,
      "step": 80
    },
    {
      "epoch": 0.07708779443254818,
      "grad_norm": 0.8082346320152283,
      "learning_rate": 7.606837606837607e-05,
      "loss": 1.6086,
      "step": 90
    },
    {
      "epoch": 0.08565310492505353,
      "grad_norm": 0.7313781380653381,
      "learning_rate": 8.461538461538461e-05,
      "loss": 1.7184,
      "step": 100
    },
    {
      "epoch": 0.09421841541755889,
      "grad_norm": 0.6124398708343506,
      "learning_rate": 9.316239316239317e-05,
      "loss": 1.5667,
      "step": 110
    },
    {
      "epoch": 0.10278372591006424,
      "grad_norm": 0.7939331531524658,
      "learning_rate": 9.990986931050022e-05,
      "loss": 1.6999,
      "step": 120
    },
    {
      "epoch": 0.11134903640256959,
      "grad_norm": 0.752505898475647,
      "learning_rate": 9.945921586300135e-05,
      "loss": 1.7245,
      "step": 130
    },
    {
      "epoch": 0.11991434689507495,
      "grad_norm": 0.7032214403152466,
      "learning_rate": 9.900856241550249e-05,
      "loss": 1.6695,
      "step": 140
    },
    {
      "epoch": 0.1284796573875803,
      "grad_norm": 0.8555830717086792,
      "learning_rate": 9.85579089680036e-05,
      "loss": 1.6339,
      "step": 150
    },
    {
      "epoch": 0.13704496788008566,
      "grad_norm": 0.6231279969215393,
      "learning_rate": 9.810725552050474e-05,
      "loss": 1.7096,
      "step": 160
    },
    {
      "epoch": 0.145610278372591,
      "grad_norm": 0.8444440364837646,
      "learning_rate": 9.765660207300586e-05,
      "loss": 1.5412,
      "step": 170
    },
    {
      "epoch": 0.15417558886509636,
      "grad_norm": 0.6882805824279785,
      "learning_rate": 9.720594862550699e-05,
      "loss": 1.6214,
      "step": 180
    },
    {
      "epoch": 0.16274089935760172,
      "grad_norm": 0.7651384472846985,
      "learning_rate": 9.675529517800813e-05,
      "loss": 1.5707,
      "step": 190
    },
    {
      "epoch": 0.17130620985010706,
      "grad_norm": 0.7237261533737183,
      "learning_rate": 9.630464173050925e-05,
      "loss": 1.5302,
      "step": 200
    },
    {
      "epoch": 0.17987152034261242,
      "grad_norm": 0.7273069620132446,
      "learning_rate": 9.585398828301037e-05,
      "loss": 1.6612,
      "step": 210
    },
    {
      "epoch": 0.18843683083511778,
      "grad_norm": 0.7945975065231323,
      "learning_rate": 9.54033348355115e-05,
      "loss": 1.5591,
      "step": 220
    },
    {
      "epoch": 0.19700214132762311,
      "grad_norm": 0.887984573841095,
      "learning_rate": 9.495268138801262e-05,
      "loss": 1.5807,
      "step": 230
    },
    {
      "epoch": 0.20556745182012848,
      "grad_norm": 0.788874626159668,
      "learning_rate": 9.450202794051375e-05,
      "loss": 1.4866,
      "step": 240
    },
    {
      "epoch": 0.21413276231263384,
      "grad_norm": 0.8218352198600769,
      "learning_rate": 9.405137449301487e-05,
      "loss": 1.4491,
      "step": 250
    },
    {
      "epoch": 0.22269807280513917,
      "grad_norm": 0.8343517184257507,
      "learning_rate": 9.3600721045516e-05,
      "loss": 1.5961,
      "step": 260
    },
    {
      "epoch": 0.23126338329764454,
      "grad_norm": 0.8346872925758362,
      "learning_rate": 9.315006759801714e-05,
      "loss": 1.6958,
      "step": 270
    },
    {
      "epoch": 0.2398286937901499,
      "grad_norm": 0.6948093175888062,
      "learning_rate": 9.269941415051826e-05,
      "loss": 1.6659,
      "step": 280
    },
    {
      "epoch": 0.24839400428265523,
      "grad_norm": 0.6990008354187012,
      "learning_rate": 9.224876070301939e-05,
      "loss": 1.7459,
      "step": 290
    },
    {
      "epoch": 0.2569593147751606,
      "grad_norm": 0.7007930278778076,
      "learning_rate": 9.179810725552051e-05,
      "loss": 1.6477,
      "step": 300
    },
    {
      "epoch": 0.26552462526766596,
      "grad_norm": 0.6341295838356018,
      "learning_rate": 9.134745380802163e-05,
      "loss": 1.4061,
      "step": 310
    },
    {
      "epoch": 0.2740899357601713,
      "grad_norm": 0.6669114828109741,
      "learning_rate": 9.089680036052276e-05,
      "loss": 1.6107,
      "step": 320
    },
    {
      "epoch": 0.2826552462526767,
      "grad_norm": 0.7827123999595642,
      "learning_rate": 9.044614691302388e-05,
      "loss": 1.5219,
      "step": 330
    },
    {
      "epoch": 0.291220556745182,
      "grad_norm": 0.7850533127784729,
      "learning_rate": 8.999549346552502e-05,
      "loss": 1.6712,
      "step": 340
    },
    {
      "epoch": 0.29978586723768735,
      "grad_norm": 0.8504790663719177,
      "learning_rate": 8.954484001802615e-05,
      "loss": 1.6354,
      "step": 350
    },
    {
      "epoch": 0.3083511777301927,
      "grad_norm": 0.7748332619667053,
      "learning_rate": 8.909418657052727e-05,
      "loss": 1.562,
      "step": 360
    },
    {
      "epoch": 0.3169164882226981,
      "grad_norm": 0.7512773871421814,
      "learning_rate": 8.86435331230284e-05,
      "loss": 1.6691,
      "step": 370
    },
    {
      "epoch": 0.32548179871520344,
      "grad_norm": 0.8614809513092041,
      "learning_rate": 8.819287967552952e-05,
      "loss": 1.4444,
      "step": 380
    },
    {
      "epoch": 0.3340471092077088,
      "grad_norm": 0.9004563689231873,
      "learning_rate": 8.774222622803064e-05,
      "loss": 1.6005,
      "step": 390
    },
    {
      "epoch": 0.3426124197002141,
      "grad_norm": 0.8203999996185303,
      "learning_rate": 8.729157278053177e-05,
      "loss": 1.5029,
      "step": 400
    },
    {
      "epoch": 0.3511777301927195,
      "grad_norm": 0.902726411819458,
      "learning_rate": 8.684091933303289e-05,
      "loss": 1.4099,
      "step": 410
    },
    {
      "epoch": 0.35974304068522484,
      "grad_norm": 0.7868928909301758,
      "learning_rate": 8.639026588553403e-05,
      "loss": 1.5698,
      "step": 420
    },
    {
      "epoch": 0.3683083511777302,
      "grad_norm": 0.8516673445701599,
      "learning_rate": 8.593961243803516e-05,
      "loss": 1.6696,
      "step": 430
    },
    {
      "epoch": 0.37687366167023556,
      "grad_norm": 0.7523463368415833,
      "learning_rate": 8.548895899053628e-05,
      "loss": 1.4591,
      "step": 440
    },
    {
      "epoch": 0.3854389721627409,
      "grad_norm": 0.7555617094039917,
      "learning_rate": 8.503830554303741e-05,
      "loss": 1.5672,
      "step": 450
    },
    {
      "epoch": 0.39400428265524623,
      "grad_norm": 0.7448047995567322,
      "learning_rate": 8.458765209553853e-05,
      "loss": 1.6362,
      "step": 460
    },
    {
      "epoch": 0.4025695931477516,
      "grad_norm": 0.7250834107398987,
      "learning_rate": 8.413699864803967e-05,
      "loss": 1.5162,
      "step": 470
    },
    {
      "epoch": 0.41113490364025695,
      "grad_norm": 0.7308099865913391,
      "learning_rate": 8.368634520054078e-05,
      "loss": 1.5461,
      "step": 480
    },
    {
      "epoch": 0.4197002141327623,
      "grad_norm": 0.7591457366943359,
      "learning_rate": 8.32356917530419e-05,
      "loss": 1.6222,
      "step": 490
    },
    {
      "epoch": 0.4282655246252677,
      "grad_norm": 0.7788330912590027,
      "learning_rate": 8.278503830554304e-05,
      "loss": 1.7213,
      "step": 500
    },
    {
      "epoch": 0.43683083511777304,
      "grad_norm": 0.7616892457008362,
      "learning_rate": 8.233438485804417e-05,
      "loss": 1.5714,
      "step": 510
    },
    {
      "epoch": 0.44539614561027835,
      "grad_norm": 0.7596190571784973,
      "learning_rate": 8.188373141054529e-05,
      "loss": 1.5667,
      "step": 520
    },
    {
      "epoch": 0.4539614561027837,
      "grad_norm": 0.7237843871116638,
      "learning_rate": 8.143307796304642e-05,
      "loss": 1.5424,
      "step": 530
    },
    {
      "epoch": 0.4625267665952891,
      "grad_norm": 0.7724266648292542,
      "learning_rate": 8.098242451554756e-05,
      "loss": 1.4841,
      "step": 540
    },
    {
      "epoch": 0.47109207708779444,
      "grad_norm": 0.8442334532737732,
      "learning_rate": 8.053177106804868e-05,
      "loss": 1.504,
      "step": 550
    },
    {
      "epoch": 0.4796573875802998,
      "grad_norm": 0.7304705381393433,
      "learning_rate": 8.008111762054981e-05,
      "loss": 1.29,
      "step": 560
    },
    {
      "epoch": 0.48822269807280516,
      "grad_norm": 0.7294108271598816,
      "learning_rate": 7.963046417305093e-05,
      "loss": 1.4883,
      "step": 570
    },
    {
      "epoch": 0.49678800856531047,
      "grad_norm": 0.7287592887878418,
      "learning_rate": 7.917981072555205e-05,
      "loss": 1.5957,
      "step": 580
    },
    {
      "epoch": 0.5053533190578159,
      "grad_norm": 0.769774317741394,
      "learning_rate": 7.872915727805318e-05,
      "loss": 1.5626,
      "step": 590
    },
    {
      "epoch": 0.5139186295503212,
      "grad_norm": 0.8254895806312561,
      "learning_rate": 7.82785038305543e-05,
      "loss": 1.5863,
      "step": 600
    },
    {
      "epoch": 0.5224839400428265,
      "grad_norm": 0.7558397650718689,
      "learning_rate": 7.782785038305543e-05,
      "loss": 1.4512,
      "step": 610
    },
    {
      "epoch": 0.5310492505353319,
      "grad_norm": 0.7562167048454285,
      "learning_rate": 7.737719693555657e-05,
      "loss": 1.4046,
      "step": 620
    },
    {
      "epoch": 0.5396145610278372,
      "grad_norm": 0.7081997394561768,
      "learning_rate": 7.692654348805769e-05,
      "loss": 1.5316,
      "step": 630
    },
    {
      "epoch": 0.5481798715203426,
      "grad_norm": 0.7822368144989014,
      "learning_rate": 7.647589004055882e-05,
      "loss": 1.4722,
      "step": 640
    },
    {
      "epoch": 0.556745182012848,
      "grad_norm": 0.7227791547775269,
      "learning_rate": 7.602523659305994e-05,
      "loss": 1.5311,
      "step": 650
    },
    {
      "epoch": 0.5653104925053534,
      "grad_norm": 0.7902345061302185,
      "learning_rate": 7.557458314556106e-05,
      "loss": 1.4429,
      "step": 660
    },
    {
      "epoch": 0.5738758029978587,
      "grad_norm": 0.6761276125907898,
      "learning_rate": 7.51239296980622e-05,
      "loss": 1.4754,
      "step": 670
    },
    {
      "epoch": 0.582441113490364,
      "grad_norm": 0.7284558415412903,
      "learning_rate": 7.467327625056331e-05,
      "loss": 1.4692,
      "step": 680
    },
    {
      "epoch": 0.5910064239828694,
      "grad_norm": 0.7337095737457275,
      "learning_rate": 7.422262280306445e-05,
      "loss": 1.542,
      "step": 690
    },
    {
      "epoch": 0.5995717344753747,
      "grad_norm": 0.7409453392028809,
      "learning_rate": 7.377196935556558e-05,
      "loss": 1.6299,
      "step": 700
    },
    {
      "epoch": 0.6081370449678801,
      "grad_norm": 0.7770983576774597,
      "learning_rate": 7.33213159080667e-05,
      "loss": 1.5317,
      "step": 710
    },
    {
      "epoch": 0.6167023554603854,
      "grad_norm": 0.745216429233551,
      "learning_rate": 7.287066246056783e-05,
      "loss": 1.4983,
      "step": 720
    },
    {
      "epoch": 0.6252676659528907,
      "grad_norm": 0.8451770544052124,
      "learning_rate": 7.242000901306895e-05,
      "loss": 1.6102,
      "step": 730
    },
    {
      "epoch": 0.6338329764453962,
      "grad_norm": 0.7896787524223328,
      "learning_rate": 7.196935556557008e-05,
      "loss": 1.534,
      "step": 740
    },
    {
      "epoch": 0.6423982869379015,
      "grad_norm": 0.8473169803619385,
      "learning_rate": 7.15187021180712e-05,
      "loss": 1.6718,
      "step": 750
    },
    {
      "epoch": 0.6509635974304069,
      "grad_norm": 0.8342311382293701,
      "learning_rate": 7.106804867057232e-05,
      "loss": 1.4477,
      "step": 760
    },
    {
      "epoch": 0.6595289079229122,
      "grad_norm": 0.84610915184021,
      "learning_rate": 7.061739522307346e-05,
      "loss": 1.4006,
      "step": 770
    },
    {
      "epoch": 0.6680942184154176,
      "grad_norm": 0.7733731269836426,
      "learning_rate": 7.016674177557459e-05,
      "loss": 1.5484,
      "step": 780
    },
    {
      "epoch": 0.6766595289079229,
      "grad_norm": 0.7983523011207581,
      "learning_rate": 6.971608832807571e-05,
      "loss": 1.526,
      "step": 790
    },
    {
      "epoch": 0.6852248394004282,
      "grad_norm": 0.669215977191925,
      "learning_rate": 6.926543488057684e-05,
      "loss": 1.5537,
      "step": 800
    },
    {
      "epoch": 0.6937901498929336,
      "grad_norm": 0.7070121765136719,
      "learning_rate": 6.881478143307796e-05,
      "loss": 1.5236,
      "step": 810
    },
    {
      "epoch": 0.702355460385439,
      "grad_norm": 0.7660633325576782,
      "learning_rate": 6.83641279855791e-05,
      "loss": 1.4985,
      "step": 820
    },
    {
      "epoch": 0.7109207708779444,
      "grad_norm": 0.6315531730651855,
      "learning_rate": 6.791347453808023e-05,
      "loss": 1.5572,
      "step": 830
    },
    {
      "epoch": 0.7194860813704497,
      "grad_norm": 0.6913293600082397,
      "learning_rate": 6.746282109058134e-05,
      "loss": 1.5278,
      "step": 840
    },
    {
      "epoch": 0.728051391862955,
      "grad_norm": 0.7944601774215698,
      "learning_rate": 6.701216764308247e-05,
      "loss": 1.498,
      "step": 850
    },
    {
      "epoch": 0.7366167023554604,
      "grad_norm": 0.9485140442848206,
      "learning_rate": 6.65615141955836e-05,
      "loss": 1.5707,
      "step": 860
    },
    {
      "epoch": 0.7451820128479657,
      "grad_norm": 0.8137423992156982,
      "learning_rate": 6.611086074808472e-05,
      "loss": 1.6393,
      "step": 870
    },
    {
      "epoch": 0.7537473233404711,
      "grad_norm": 0.8314968347549438,
      "learning_rate": 6.566020730058585e-05,
      "loss": 1.578,
      "step": 880
    },
    {
      "epoch": 0.7623126338329764,
      "grad_norm": 0.794853925704956,
      "learning_rate": 6.520955385308697e-05,
      "loss": 1.5961,
      "step": 890
    },
    {
      "epoch": 0.7708779443254818,
      "grad_norm": 0.7887436151504517,
      "learning_rate": 6.475890040558811e-05,
      "loss": 1.6414,
      "step": 900
    },
    {
      "epoch": 0.7794432548179872,
      "grad_norm": 0.8325908184051514,
      "learning_rate": 6.430824695808924e-05,
      "loss": 1.6104,
      "step": 910
    },
    {
      "epoch": 0.7880085653104925,
      "grad_norm": 0.7706311941146851,
      "learning_rate": 6.385759351059036e-05,
      "loss": 1.43,
      "step": 920
    },
    {
      "epoch": 0.7965738758029979,
      "grad_norm": 0.7421631217002869,
      "learning_rate": 6.34069400630915e-05,
      "loss": 1.731,
      "step": 930
    },
    {
      "epoch": 0.8051391862955032,
      "grad_norm": 0.8399296998977661,
      "learning_rate": 6.295628661559261e-05,
      "loss": 1.4478,
      "step": 940
    },
    {
      "epoch": 0.8137044967880086,
      "grad_norm": 0.7759097218513489,
      "learning_rate": 6.250563316809373e-05,
      "loss": 1.4641,
      "step": 950
    },
    {
      "epoch": 0.8222698072805139,
      "grad_norm": 0.7985116839408875,
      "learning_rate": 6.205497972059487e-05,
      "loss": 1.642,
      "step": 960
    },
    {
      "epoch": 0.8308351177730193,
      "grad_norm": 0.8221399188041687,
      "learning_rate": 6.160432627309599e-05,
      "loss": 1.6527,
      "step": 970
    },
    {
      "epoch": 0.8394004282655246,
      "grad_norm": 0.8118009567260742,
      "learning_rate": 6.115367282559712e-05,
      "loss": 1.6216,
      "step": 980
    },
    {
      "epoch": 0.8479657387580299,
      "grad_norm": 0.8193336129188538,
      "learning_rate": 6.0703019378098245e-05,
      "loss": 1.4991,
      "step": 990
    },
    {
      "epoch": 0.8565310492505354,
      "grad_norm": 0.8225547671318054,
      "learning_rate": 6.025236593059937e-05,
      "loss": 1.606,
      "step": 1000
    },
    {
      "epoch": 0.8650963597430407,
      "grad_norm": 0.8435539603233337,
      "learning_rate": 5.9801712483100505e-05,
      "loss": 1.5106,
      "step": 1010
    },
    {
      "epoch": 0.8736616702355461,
      "grad_norm": 0.787751317024231,
      "learning_rate": 5.935105903560163e-05,
      "loss": 1.5867,
      "step": 1020
    },
    {
      "epoch": 0.8822269807280514,
      "grad_norm": 0.7960286736488342,
      "learning_rate": 5.8900405588102744e-05,
      "loss": 1.6541,
      "step": 1030
    },
    {
      "epoch": 0.8907922912205567,
      "grad_norm": 0.5941848754882812,
      "learning_rate": 5.844975214060388e-05,
      "loss": 1.4345,
      "step": 1040
    },
    {
      "epoch": 0.8993576017130621,
      "grad_norm": 0.8133092522621155,
      "learning_rate": 5.7999098693105004e-05,
      "loss": 1.5704,
      "step": 1050
    },
    {
      "epoch": 0.9079229122055674,
      "grad_norm": 0.7475671768188477,
      "learning_rate": 5.754844524560613e-05,
      "loss": 1.5228,
      "step": 1060
    },
    {
      "epoch": 0.9164882226980728,
      "grad_norm": 0.7967726588249207,
      "learning_rate": 5.7097791798107256e-05,
      "loss": 1.7172,
      "step": 1070
    },
    {
      "epoch": 0.9250535331905781,
      "grad_norm": 0.7912998795509338,
      "learning_rate": 5.664713835060839e-05,
      "loss": 1.4574,
      "step": 1080
    },
    {
      "epoch": 0.9336188436830836,
      "grad_norm": 0.7667267918586731,
      "learning_rate": 5.6196484903109516e-05,
      "loss": 1.5327,
      "step": 1090
    },
    {
      "epoch": 0.9421841541755889,
      "grad_norm": 0.8932487368583679,
      "learning_rate": 5.574583145561064e-05,
      "loss": 1.6317,
      "step": 1100
    },
    {
      "epoch": 0.9507494646680942,
      "grad_norm": 0.7684940099716187,
      "learning_rate": 5.529517800811177e-05,
      "loss": 1.6299,
      "step": 1110
    },
    {
      "epoch": 0.9593147751605996,
      "grad_norm": 0.8092303276062012,
      "learning_rate": 5.484452456061289e-05,
      "loss": 1.3215,
      "step": 1120
    },
    {
      "epoch": 0.9678800856531049,
      "grad_norm": 0.7707965970039368,
      "learning_rate": 5.4393871113114015e-05,
      "loss": 1.5176,
      "step": 1130
    },
    {
      "epoch": 0.9764453961456103,
      "grad_norm": 0.803207516670227,
      "learning_rate": 5.394321766561514e-05,
      "loss": 1.4686,
      "step": 1140
    },
    {
      "epoch": 0.9850107066381156,
      "grad_norm": 0.7581740021705627,
      "learning_rate": 5.349256421811627e-05,
      "loss": 1.566,
      "step": 1150
    },
    {
      "epoch": 0.9935760171306209,
      "grad_norm": 0.87521892786026,
      "learning_rate": 5.30419107706174e-05,
      "loss": 1.5529,
      "step": 1160
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.490552544593811,
      "eval_runtime": 44.6616,
      "eval_samples_per_second": 26.152,
      "eval_steps_per_second": 6.538,
      "step": 1168
    }
  ],
  "logging_steps": 10,
  "max_steps": 2336,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.816764977433805e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
